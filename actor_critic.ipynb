{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Box(1,)\n"
     ]
    }
   ],
   "source": [
    "# 環境構築\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "\n",
    "print( env.action_space )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 観測\n",
    "a_state = tf.placeholder(tf.float32, [None, state_dim])\n",
    "\n",
    "# Criticから渡される勾配\n",
    "a_action_grads = tf.placeholder(tf.float32, [None, act_dim])\n",
    "\n",
    "# ネットワーク構築\n",
    "with tf.variable_scope(\"actor\"):\n",
    "    fc1 = tf.contrib.layers.fully_connected(a_state, 400 )\n",
    "    fc2 = tf.contrib.layers.fully_connected(fc1, 300)\n",
    "    fc3 = tf.contrib.layers.fully_connected(fc2, act_dim, activation_fn=tf.tanh )\n",
    "    a_output = tf.multiply(fc3, 1)\n",
    "\n",
    "# 勾配を計算\n",
    "a_params = [ v for v in tf.trainable_variables() if \"actor\" in v.name ]\n",
    "a_grads = tf.gradients(a_output, a_params, -a_action_grads)\n",
    "a_grads = list(map(lambda x: tf.div(x, 20),  a_grads))\n",
    "\n",
    "# 最適化\n",
    "a_train_step = tf.train.AdamOptimizer(0.0001).apply_gradients(zip(a_grads,  a_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic\n",
    "c_state = tf.placeholder(tf.float32, [None, state_dim])\n",
    "c_action = tf.placeholder(tf.float32, [None, act_dim])\n",
    "c_target_q = tf.placeholder(tf.float32, [None, act_dim])\n",
    "\n",
    "fc1 = tf.contrib.layers.fully_connected(c_state, 400)\n",
    "w1 = tf.Variable(tf.random_normal([400, 300], mean=0.0, stddev=0.05))\n",
    "w2 = tf.Variable(tf.random_normal([act_dim, 300], mean=0.0, stddev=0.05))\n",
    "b2 = tf.Variable(tf.zeros([300]))\n",
    "\n",
    "# 二層目でactionと結合\n",
    "fc2 = tf.nn.relu(tf.matmul(fc1, w1) + tf.matmul(c_action, w2) + b2)\n",
    "c_output = tf.contrib.layers.fully_connected(fc2, act_dim, activation_fn=None)\n",
    "\n",
    "c_loss = tf.reduce_mean(tf.square(c_target_q - c_output))\n",
    "\n",
    "#c_loss = tf.losses.huber_loss(c_target_q, c_output)\n",
    "c_train_step = tf.train.AdamOptimizer(0.001).minimize(c_loss)\n",
    "c_action_grads = tf.gradients(c_output, c_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experinece Rplay用のメモリ\n",
    "memory = deque(maxlen=10000)\n",
    "\n",
    "def sample( memory, batch_size ):\n",
    "    samp = random.sample( memory, batch_size )\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    \n",
    "    for s, a, r, ns in samp:\n",
    "        states.append( s )\n",
    "        actions.append( a )\n",
    "        rewards.append( r )\n",
    "        next_states.append( ns )\n",
    "    return np.array(states), np.array(actions), np.array(rewards), np.array(next_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモリにランダムの経験を入れる\n",
    "memory.clear()\n",
    "\n",
    "env.reset()\n",
    "action = env.action_space.sample()\n",
    "state, reward, done, _ = env.step(action)\n",
    "for i in range(1, 100):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.append((state, action, reward, next_state))\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -194.46498162010894\n",
      "1 -193.1384991781803\n",
      "2 -186.90858367258895\n",
      "3 -200.31313177618057\n",
      "4 -146.60679714588588\n",
      "5 -173.30712492785548\n",
      "6 -153.94330900944902\n",
      "7 -165.26276282763777\n",
      "8 -195.688743343262\n",
      "9 -185.31600588199487\n",
      "10 -184.0525121419867\n",
      "11 -168.33288204571673\n",
      "12 -165.98387419280706\n",
      "13 -172.44140156953628\n",
      "14 -158.526974933941\n",
      "15 -163.82903145585664\n",
      "16 -159.75742756215496\n",
      "17 -159.4248071254868\n",
      "18 -174.10655074269513\n",
      "19 -179.43940193693587\n",
      "20 -206.72110257906024\n",
      "21 -188.82175516314595\n",
      "22 -189.42101787512328\n",
      "23 -190.654174641023\n",
      "24 -42.082720069770815\n",
      "25 -197.55965811241873\n",
      "26 -197.58623741389653\n",
      "27 -183.81051259904226\n",
      "28 -182.88170021715464\n",
      "29 -36.58178904886523\n",
      "30 -193.55772272708066\n",
      "31 -187.27502485442037\n",
      "32 -197.71038215637702\n",
      "33 -191.13178171848745\n",
      "34 -195.09807122234412\n",
      "35 -205.47758082517777\n",
      "36 -198.76777750167471\n",
      "37 -204.3350423261247\n",
      "38 -182.1672896344073\n",
      "39 -196.05602919848482\n",
      "40 -211.37165623054426\n",
      "41 -215.32935249552744\n",
      "42 -213.2715205274847\n",
      "43 -207.08421659709435\n",
      "44 -191.48096306966303\n",
      "45 -197.95583342201294\n",
      "46 -189.4740373367686\n",
      "47 -193.0570846340275\n",
      "48 -197.6927451489903\n",
      "49 -80.72599645616361\n",
      "50 -214.77835905475382\n",
      "51 -41.87673120659542\n",
      "52 -203.05220960625687\n",
      "53 -187.72797637111142\n",
      "54 -205.55027835157622\n",
      "55 66.07372738837906\n",
      "56 -79.12531277451924\n",
      "57 68.25636746803895\n",
      "58 71.27408085699275\n",
      "59 78.32133145059942\n",
      "60 73.46307233609684\n",
      "61 74.54627275410148\n",
      "62 82.07096981069884\n",
      "63 -92.58842241263135\n",
      "64 -192.29921373298524\n",
      "65 -192.4053580395236\n",
      "66 -68.98965511229228\n",
      "67 -75.01731737990326\n",
      "68 38.23302801591963\n",
      "69 -198.7110149143264\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-4c73c995d9ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# 実際に行動\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ma_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ma_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/gym/envs/classic_control/continuous_mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/pyglet/window/cocoa/__init__.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_mouse_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/pyglet/gl/cocoa.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nscontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflushBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/pyglet/libs/darwin/cocoapy/runtime.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;34m\"\"\"Call the method with the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/envs/tf130/lib/python3.6/site-packages/pyglet/libs/darwin/cocoapy/runtime.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, objc_id, *args)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;31m# Convert result to python type if it is a instance or class pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mObjCInstance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run( tf.global_variables_initializer() )\n",
    "    for ep in range(1000):\n",
    "        total_reward = 0\n",
    "        env.reset()\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        state, reward, done, _ = env.step(action)\n",
    "        # 学習\n",
    "        for it in range(1000):\n",
    "            # メモリから20個取り出す\n",
    "            states, actions, rewards, next_states = sample( memory, 20 )\n",
    "                        \n",
    "            # 次の状態next_stateで取るべき行動next_actionを予測\n",
    "            next_actions = sess.run( a_output, feed_dict={a_state: next_states} )\n",
    "            \n",
    "            # 次の状態の価値を計算\n",
    "            next_q = sess.run( c_output, feed_dict={c_state:next_states, c_action: next_actions} )\n",
    "            \n",
    "            # critic学習\n",
    "            # 今の状態と行動のQ値を更新\n",
    "            # rewards: 今の状態と行動で得られた報酬\n",
    "            # next_q: 遷移先のQ値\n",
    "            feed_dict = {\n",
    "                c_state: states, \n",
    "                c_action: actions, \n",
    "                c_target_q: rewards.reshape(20,1) + 0.99 * next_q\n",
    "            }\n",
    "            sess.run( c_train_step , feed_dict=feed_dict)\n",
    "            \n",
    "            # Q値が最大となるようなactionの勾配を計算\n",
    "            feed_dict = {\n",
    "                c_state: states,\n",
    "                c_action: actions\n",
    "            }\n",
    "            action_grads = sess.run( c_action_grads, feed_dict=feed_dict )[0]\n",
    "            \n",
    "            # actor学習\n",
    "            feed_dict = {\n",
    "                a_state: states,\n",
    "                a_action_grads: action_grads                \n",
    "            }\n",
    "            sess.run( a_train_step, feed_dict=feed_dict )\n",
    "                        \n",
    "            # 実際に行動\n",
    "            if ep%10==0:\n",
    "                env.render()\n",
    "            action = sess.run( a_output, feed_dict={a_state: state.reshape(-1,state_dim)} )[0]\n",
    "            action += np.random.randn()/1.0\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.append( (state.flatten(), action, reward, next_state) )\n",
    "\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        print(ep, total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
